/*! \file */


//-----------------------------------------------------------
/*! \page testing Testing

   http://check.sourceforge.net/

explain the framework and usual way to use it.

need to explain how to write the testing stuff in special C comments.


give the behind-the-scenes of what happens when one types 'make test'



next: \ref documentation
*/



//-----------------------------------------------------------
/*! \page documentation Documentation

doxygen

and what parts there are that must be included.

idea to write it before the function is written

next: \ref file_format
*/



//-----------------------------------------------------------
/*! \page file_format File Format


This is a brief overview of the object implementation in an HDF5 file.
There are basically 3 different objects that HDF5 defines: metadata,
groups, and datasets.
Groups are basically like directories in a filesystem, with names and
metadata attached to them.
Datasets are basically like files in  a filesystem, with names and
metadata attached to them.
We use these 3 HDF5 objects to create our own "meta" objects.

\section file_format_file_metadata File Metadata
\addindex File Metadata Format

There is an "HDF5 Group," named \c _Header
   which contains "file" metadata:
\li   grouptype,          Value: "Metadata"
\li   filetype,           Value: "GEOSCIPY"
\li   software_version,   Value: "V0.0.1"
\li   descriptor 
\li   creation_datetime
\li   last_update_datetime
\li   history

   The descriptor is set by the user.
   The history is added-on to during the lifetime
   of the file. It keeps track of everything that
   is done to the file.
   datetime's look like: "15:50:36 12-Apr-2014"
   and help keep track of things.
   Each history line-item is tagged with a datetime.

   Other objects are created as "HDF5 Groups" under "/,"
   (the root) with metadata and data beneath the group.


\section file_format_image_objects Image Objects
\addindex Image Object File Format


Image objects are created as groups.
   They have the following metadata attached to them:

\li   grouptype,       Value: "Image"
\li   descriptor
\li   creation_datetime
\li   last_update_datetime
\li   history
\li   DUMP: pixel_size_units, Typical Value: "meter"
\li   DUMP: pixel_size_x
\li   DUMP: pixel_size_y
\li   type   
\li   nchannels
\li   DUMP: npixels
\li   DUMP: nlines
\li   writeable
\li   spatialref
\li   DUMP: location

   Some metadata is actually datasets:
   location,
   rawheader, and
   sarheader.

   The idea behind a multi-channel image is that it should hold all the
   channels that the user would like to group together as a single
   unit.
   For polarimetric SAR data, all the channels of the covariance
   should be kept together in one image, to be operated on together.
   For multispectral data, like Landsat, all 7 channels need to be
   kept together, even though the resolution, and hence number of
   pixels, is different for some of the channels.

   The descriptor is set by the user.
   The history is added-on to during the lifetime
   of the image. It keeps track of everything that
   is done to the image.
   datetime's look like: "15:50:36 12-Apr-2014"
   and help keep track of things.
   Each history line-item is tagged with a datetime.

   DUMP: 
   The pixel-sizes are given in the \c x and \c y directions,
   and they have units. These can all be updated as needed.
   
   The type is a string of comma-separated type-strings.
   the type-strings can be one of:
    \c "UINT1",
    \c "UINT8",
    \c "INT8",
    \c "CINT8",
    \c "UINT16",
    \c "INT16",
    \c "CINT16",
    \c "UINT32",
    \c "INT32",
    \c "UINT64",
    \c "INT64",
    \c "CINT32",
    \c "CINT64",
    \c "R32",
    \c "R64",
    \c "C64",
    \c "C128".
    This covers all the basic types that are possible: integers,
    reals, complex numbers, with sizes of 1 bit, 1 byte, 2 byte, 4
    bytes, or 8 bytes.
    These strings can be decoded by noting that U
    stands for Unsigned, C stands for Complex, R
    stands for Real, INT stands for Integer, and the
    number at the end is the number of bits in the value.
    For example:

\li       \c "UINT32" is an unsigned 32-bit integer
\li       \c "CINT64" is a complex 64-bit integer.
                It's real-part is represented with a 32-integer,
                it's imaginary-part represented with a 32-bit integer.
\li       \c "C128"   is a complex 128-bit floating-point  value.
                It's real part: 64-bit real number (double),
                it's imag part: 64-bit real number (double).
\li       \c "UINT1"  is an unsigned 1-bit integer (a bitmap).

    An example type string looks like:
      \c "R32",\c "C64",\c "UINT1"
    which means that channel-1 is a 32-bit real number,
                     channel-2 is a 64-bit complex floating-point number
                     channel-3 is a 1-bit integer (0 or 1).

    The metadata "writeable" is likewise a comma-separated list,
    containing a 0 if the channel is write-locked, 
    and a 1 if the channel is writeable.

    The metadata "nchannels" is a single integer giving the number
    of channels.

    DUMP:
    "npixels" is the count of pixels in the x-direction,
    "nlines" is the count of pixels in the y-direction.

    The metadata "spatialref" is a string contianing the EPSG (or other) code,
    the wkt string, and the proj.4 string.

    DUMP:
    The metadata "location" is straightforward copy of the \c Location_t structure,
    with either an affine transform to the projected coords: (x0,y0),
    (dx,dy), etc., or a list of GCPs giving image coords and
    projected coords for up to 100 points. This is all stored in a
    simple dataset.

    The metadata  "rawheader" is a dataset containing whatever the raw header of the
    image data was. This is binary bytes.

    The metadata  "sarheader" is a copy of the \c SARMetadata_t structure, converted 
    to ascii for ease of reading/writing/viewing. All stored in an
    "IFile" dataset, for ease of reading/writing/extending.
    

\subsection fiel_format_image_data Image Data
\addindex Image Data File Format

    Each channel in an image is a separate "HDF5 Dataset" within
    the image group.
    These are called "rasters."
    The names of each of these raster channels is \c "r%d" where \c %d is replaced
    by the integer value of the channel number.
    Channel numbers start at 1 and are contiguous.
   
    Images can also have image pyramid data associated with them.
    These are also "HDF5 Datasets," and are named "p%d_%dX%d"
    where the first \c %d is the channel number they are associated with,
    the secondc %d is the x-dimension in pixels, and the 3rd \c %d is
    the y-dimension in pixels.
    As the pyramids are meant solely for speeding up the GUI, they are
    not mentioned in the metadata, and the code has to "look for"
    them.

    Each raster dataset also has metadata:

\li    dataset_type,         Value: "2"
\li    descriptor
\li    last_update_datetime
\li   ADD: pixel\_size\_units, Typical Value: "meter"
\li   ADD: pixel\_size\_x
\li   ADD: pixel\_size\_y
\li   ADD: npixels
\li   ADD: nlines
\li   ADD: location

    There are 2 possible values for the \c dataset_type: "1" is for "internal files,"
    and "2" is for image raster data.

   The "pixel-size" parameters are given in the \c x and \c y directions,
   and they have units. These can all be updated as needed.

    "npixels" is the count of pixels in the x-direction,
    "nlines" is the count of pixels in the y-direction.

    The metadata "location" is straightforward copy of the \c Location_t structure,
    with either an affine transform to the projected coords: (x0,y0),
    (dx,dy), etc., or a list of GCPs giving image coords and
    projected coords for up to 100 points. This is all stored in a
    simple dataset YET: in XML format.



\subsection file_format_iamge_pyramids Image Pyramids
\addindex Image Pyramids File Format

 Image objects can contain other datasets besides the rasters.
    In particular, they can contain "image pyramids" named
    \c "p%d_xsizeXysize" where the first \c %d is the channel number they
    correspond to, and the xsizeXysize is the shrunken size of each:
    there may be many.
    These datasets (as well as the rasters) have \c last-update-datetime's so that
    a program can decide to recompute the pyramids \a if they are older
    than the image rasters they go with.
    These datasets do not have "writeable" metdata so they are always
    read/write.


\subsection file_format_other_metadata Other Metadata
\addindex Other Metadata File Format

    There is also metadata stored in datasets, basically like an
    ordinary file, but within the HDF file structure.

    So far, there are 3 metadata-datasets: for sar metadata, for
    location metadata, and for raw image metadata.

    The "location" metadata is stored for each raster image, and
    this dataset also has
    \c writeable metadata as well as \c descriptor, \c type (3), and
    \c last_update_datetime. 
    The data is stored in a binary form for efficiency.

    The sar metadata is an ascii XML-encoded (YET) set of variables that is
    consistent for all SAR data that the system can import.
    This dataset also has
    \c writeable metadata as well as \c descriptor, \c type (3), and
    \c last_update_datetime. 
    
    For completeness, every dataset that is imported also has it's raw
    metadata imported along with it, and stored into a "raw image
    metadata" Dataset. 
    This is done in order to provide access to all the metadata
    provided by the data processing facility that created the dataset.
    Since this raw metadata is transformed into a stadard set, some
    of the metadata is lost, and this allows programs that need it to
    retain access to it.

    
\section file_format_vectors Vectors
\addindex Vector Object File Format

   Vector objects are also created as groups.
   They have the following metadata attached to them:

\li   grouptype, Value: "Vector"
\li   descriptor
\li   creation_datetime
\li   last_update_datetime
\li   history
\li   writeable
\li   spatialref

   yet: need to add bounds

   YET:Convert to XML
   The "spatialref" metadata string contains 3 popular ways to specify the spatial
   reference that is used to specify coordinates:
   First there is the EPSG code, then the Well-Known-Text version,
   and lastly the proj4 method, each separated with semi-colons.
   An example:

\code
       EPSG:32613; wkt:PROJCS["WGS_1984_UTM_Zone_13N",
       GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",
       SPHEROID["WGS_1984",6378137.0,298.257223563]],
       PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433],
       AUTHORITY["EPSG","4326"]],PROJECTION["Transverse_Mercator"],
       PARAMETER["False_Easting",500000.0],PARAMETER["False_Northing",0.0],
       PARAMETER["Central_Meridian",-105.0],PARAMETER["Scale_Factor",0.9996],
       PARAMETER["Latitude_Of_Origin",0.0],UNIT["Meter",1.0],
       AUTHORITY["EPSG","32613"]]; 
       proj4:+proj=utm +zone=13 +ellps=WGS84 +units=m +no_defs;
\endcode

   Note that in the actual string there are no "line-feeds" as there
   are here.

   The data that is stored in the Vector object is in an
   "HDF5 Dataset" under the named Group. This dataset is always named "ifile1."
   However, this dataset is set up as a 1-dimensional extendable
   dataset that is basically equivalent to a "file."
   It is called an IFILE, and contains all the database tables
   needed to represent the vectors in a relational-spatial database.
   The database used is spatialite
   (www.gaia-gis.it/fossil/libspatialite), 
   which is implemented on top of
   sqlite3 (www.sqlite.org). A driver was written in order to make it use the internal
   file instead of the usual file on a user's hard drive.
   This is described  in chapter \ref{object_library}, on the Object
   Library functions.

   DUMP: We have used the OGR library from Frank Warmerdam to implement
   a rudimentary Vector-Import function.
   
   
\section file_format_yet Yet to Implement
\addindex Yet to Implement File Format Features
 
LUTs, PCTS, GCPs, 

     bayesian classn signatures

     random forests data

     modality-specific header info.
     
     2d, 3d meshes

     2d, 3d triangulations

     2d, 3d objects
     
     and we can use the sqlite3 to make a standard relational
     database, instead of the spatialite database we have already       
     created for vectors.
     This can be used for std spreadsheets, etc....

     lots of arbitrary data formats for various computer codes
     can be re-created as IFILE's with minor modifications to
     the original codes (as I've implemented all the C file
     operations for IFILE's).

     is it possible to include ESMF in this?

     Need forward and inverse models of all kinds.
     
     calibration

     etc.
\endif





*/

